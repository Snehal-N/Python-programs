{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "#Read Effective and final file merged them \n",
    "\n",
    "df=pd.read_csv('Effective.csv')\n",
    "df1=pd.read_csv('Final.csv')\n",
    "\n",
    "df=df.drop(['Final Date'],axis=1)\n",
    "df=df.rename(columns={'Effective Date':'Effective/Final Date'})\n",
    "df1=df1.drop(['Effective Date'],axis=1)\n",
    "df1=df1.rename(columns={'Final Date':'Effective/Final Date'})\n",
    "\n",
    "#merging of Two files\n",
    "df_final=pd.concat([df,df1])\n",
    "\n",
    "df_final['Document Number']=df_final['Document Number'] + \".pdf\"\n",
    "df_final['Effective/Final Date']=pd.to_datetime(df_final['Effective/Final Date'])\n",
    "df_final['Effective/Final Date'] = df_final['Effective/Final Date'].dt.strftime('%m/%d/%y')\n",
    "\n",
    "\n",
    "#move document names to txt file\n",
    "\n",
    "x = \"\"\n",
    "n = len(df_final['Document Number'])\n",
    "import math\n",
    "r = math.ceil(n/400)\n",
    "for i in range(r):\n",
    "    x = \"\"\n",
    "    for p in range(400*i,400*(i+1)):\n",
    "        if p < len(df_final['Document Number']):\n",
    "            x += \" \"\n",
    "            x += df_final.iloc[p]['Document Number']\n",
    "        else: break\n",
    "                \n",
    "    file1 = open(f'SCS_E&F_{i+1}.txt', 'w')\n",
    "    file1.write(\"dir /s /t:w \")\n",
    "    file1.write(x)\n",
    "    time = datetime.today()\n",
    "    time = time.strftime(\"%d_%B\")\n",
    "    path = f\">D:\\check\\\\SCS_{time}_{i+1}.txt\"\n",
    "    file1.write(path)\n",
    "    file1.close()\n",
    "    \n",
    "\n",
    "#Export result to CSV file i.e CDOCS_Report\n",
    "\n",
    "print(len(df_final))\n",
    "today = datetime.today()\n",
    "yest = today - timedelta(days = 1)\n",
    "yest = yest.strftime(\"%d_%B\")\n",
    "\n",
    "Cdoc_report=f\"CDOCS_report_{yest}.csv\"\n",
    "df_final.to_csv(Cdoc_report,index=False)\n",
    "\n",
    "\n",
    "#Read obsolete file\n",
    "\n",
    "df_obsolete=pd.read_csv('Obsolete Documents.csv')\n",
    "df_obsolete['Document Number']=df_obsolete['Document Number'] + \".pdf\"\n",
    "df_obsolete['Comments']='Moved out of SCS'\n",
    "   #print(df_obsolete)\n",
    "obsolete_report=f\"Obsolete_report_{yest}.csv\"\n",
    "df_obsolete.to_csv(obsolete_report,index=False)    \n",
    "    \n",
    "\n",
    "\n",
    "#move document to txt file\n",
    "\n",
    "y= \"\"\n",
    "for i in df_obsolete['Document Number']:\n",
    "    y+=\" \"\n",
    "    y+=i\n",
    "    \n",
    "file2= open('SCS_Obs.txt','w')\n",
    "file2.write(\"dir /s /t:w \")\n",
    "file2.write(y)\n",
    "file2.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n"
     ]
    }
   ],
   "source": [
    "#Processing on the SCS file\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df_temp=pd.read_csv('SCS_temp.csv',encoding= 'unicode_escape',header=None)\n",
    "df_temp = df_temp[df_temp[0].str.contains(\"pdf\")]\n",
    "x = df_temp[0].str.split(' ')\n",
    "\n",
    "date  =[]\n",
    "doc = []\n",
    "for i in x:\n",
    "    date.append(i[0])\n",
    "    doc.append(i[-1])\n",
    "    \n",
    "df_temp['Modified_date']=pd.to_datetime(date)\n",
    "df_temp['Modified_date'] = df_temp['Modified_date'].dt.strftime('%m/%d/%y')\n",
    "#df_temp['Modified_date'] = datetime.strptime(df_temp['Modified_date'], '%m %d %y').date()\n",
    "df_temp['Document Number']=doc\n",
    "\n",
    "df_temp.drop(df_temp.columns[0],axis=1,inplace =True)\n",
    "#print(df_temp)\n",
    "print(len(df_temp))\n",
    "#Exporting result to csv i.e SCS Report\n",
    "df_temp.to_csv('SCS_FINAL.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n"
     ]
    }
   ],
   "source": [
    "#Checking or validation of both report for Effective date and count\n",
    "df_CDOCS = pd.read_csv(Cdoc_report)\n",
    "df_SCS = pd.read_csv('SCS_FINAL.csv')\n",
    "#print(len(df_SCS))\n",
    "\n",
    "\n",
    "inner_join = pd.merge(df_CDOCS, \n",
    "                      df_SCS, \n",
    "                      on ='Document Number', \n",
    "                      how ='right')\n",
    "#print(inner_join)\n",
    "df_new=pd.DataFrame()\n",
    "#inner_join['check']=np.where(inner_join['Modified_date'] >= inner_join['Effective/Final Date'],'True', 'False')\n",
    "inner_join['check']=pd.to_datetime(inner_join['Modified_date']) >= pd.to_datetime(inner_join['Effective/Final Date'])\n",
    "df_new['Document Number']=inner_join['Document Number']\n",
    "df_new['Modified_date']=inner_join['Modified_date']\n",
    "df_new['Effective/Final Date']=inner_join['Effective/Final Date']\n",
    "df_new['check']=inner_join['check']\n",
    "print(len(df_new))\n",
    "\n",
    "#Export all validation report to SCS_Final Report\n",
    "Scs_report=f\"SCS_report_{yest}.csv\"\n",
    "df_new.to_csv(Scs_report,index=False);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below documents are not mapped\n",
      "['REC-641793.pdf']\n"
     ]
    }
   ],
   "source": [
    "#Check the count of document from both the report(CDOCS and SCS)\n",
    "\n",
    "df_CDOCS = pd.read_csv(Cdoc_report)\n",
    "df_SCS = pd.read_csv(Scs_report)\n",
    "\n",
    "count1=len(df_CDOCS['Document Number'])\n",
    "count2=len(df_SCS['Document Number'])\n",
    "\n",
    "if count1==count2:\n",
    "    print('All documents are mapped')\n",
    "else:\n",
    "    print('Below documents are not mapped')\n",
    "    \n",
    "    left_join = pd.merge(df_CDOCS, \n",
    "                      df_SCS, \n",
    "                      on ='Document Number', \n",
    "                      how ='left')  \n",
    "    #print(left_join)\n",
    "    doc=[]\n",
    "    for i,j in zip(left_join['Modified_date'],left_join['Document Number']):\n",
    "        if pd.isna(i):\n",
    "            #result['Modified_date']=i\n",
    "            #result['Document Number']=j\n",
    "            doc.append(j)\n",
    "    print(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of non updated document 0\n",
      "list of non updated document\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Gives the list of not updated document on SCS\n",
    "\n",
    "df_SCS = pd.read_csv(Scs_report)\n",
    "#print(df_SCS)\n",
    "doc1 = []\n",
    "for i,j in zip(df_SCS['check'],df_SCS['Document Number']):\n",
    "    if i == False:\n",
    "        doc1.append(j)\n",
    "print('Count of non updated document',len(doc1))    \n",
    "print('list of non updated document')\n",
    "print(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "if os.path.isfile(r\"Effective.csv\"):\n",
    "          os.remove(r\"Effective.csv\")\n",
    "if os.path.isfile(r\"Final.csv\"):\n",
    "          os.remove(r\"Final.csv\")\n",
    "if os.path.isfile(r\"Obsolete Documents.csv\"):\n",
    "          os.remove(r\"Obsolete Documents.csv\")\n",
    "if os.path.isfile(r\"SCS_Obs.txt\"):\n",
    "          os.remove(r\"SCS_Obs.txt\")\n",
    "if os.path.isfile(r\"SCS_FINAL.csv\"):\n",
    "          os.remove(r\"SCS_FINAL.csv\")\n",
    "        \n",
    "if os.path.isfile(r\"SCS_E&F_1.txt\"):\n",
    "          os.remove(r\"SCS_E&F_1.txt\")\n",
    "if os.path.isfile(r\"SCS_E&F_2.txt\"):\n",
    "          os.remove(r\"SCS_E&F_2.txt\")\n",
    "if os.path.isfile(r\"SCS_E&F_3.txt\"):\n",
    "          os.remove(r\"SCS_E&F_3.txt\")\n",
    "if os.path.isfile(r\"SCS_E&F_4.txt\"):\n",
    "         os.remove(r\"SCS_E&F_4.txt\")\n",
    "if os.path.isfile(r\"SCS_E&F_5.txt\"):\n",
    "         os.remove(r\"SCS_E&F_5.txt\")\n",
    "\n",
    "    \n",
    "today = datetime.today() \n",
    "yest = today - timedelta(days = 1)\n",
    "yest = yest.strftime(\"%d_%B\")\n",
    "today=today.strftime(\"%d_%B\")\n",
    "directory =f\"{today}\"\n",
    "parent_dir = r\"D:\\Users\\snyayadh\\OneDrive - Amgen\\Automation\"\n",
    "path=os.path.join(parent_dir, directory) \n",
    "os.mkdir(path)\n",
    "\n",
    "cdocs_report=f\"CDOCS_report_{yest}.csv\"\n",
    "#cdocs_report=\"CDOCS_report_03_January.csv\"\n",
    "path1=os.path.join(parent_dir,cdocs_report)\n",
    "path2=f\"{path}\\{cdocs_report}\"\n",
    "shutil.move(path1, path2)\n",
    "\n",
    "scs_report=f\"SCS_report_{yest}.csv\"\n",
    "#scs_report=\"SCS_report_03_January.csv\"\n",
    "path1=os.path.join(parent_dir,scs_report)\n",
    "path2=f\"{path}\\{scs_report}\"\n",
    "\n",
    "shutil.move(path1, path2)\n",
    "\n",
    "\n",
    "obs_report=f\"Obsolete_report_{yest}.csv\"\n",
    "#obs_report=\"Obsolete_report_03_January.csv\"\n",
    "path1=os.path.join(parent_dir,obs_report)\n",
    "path2=f\"{path}\\{obs_report}\"\n",
    "\n",
    "shutil.move(path1, path2)\n",
    "print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
